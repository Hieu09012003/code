from ultralytics import YOLO
import cv2
import numpy as np
import json
import paho.mqtt.client as mqtt
from sort.sort import *
from util import get_car, read_license_plate, write_csv

# ============================
# âš™ï¸ Cáº¤U HÃŒNH MQTT + VIDEO
# ============================
ACCESS_TOKEN = "1lZGDfQeEZJ7UqV30cTh"   # Token cá»§a Raspberry Pi device
BROKER = "demo.thingsboard.io"
PORT = 1883

VIDEO_PATH = "./1007.mp4"
OUTPUT_PATH = "./output_violation.mp4"

# ============================
# âš™ï¸ Cáº¤U HÃŒNH YOLO & SORT
# ============================
coco_model = YOLO("yolov8n.pt")
license_plate_detector = YOLO("./models/license_plate.pt")
mot_tracker = Sort()

vehicles = [2, 3, 5, 7]  # car, motorcycle, bus, truck
detecting = False         # sáº½ báº­t khi cÃ³ tÃ­n hiá»‡u Ä‘Ã¨n Ä‘á» ğŸ”´

# ============================
# ğŸ§­ Tá»ŒA Äá»˜ VÃ™NG VI PHáº M
# ============================
# Äá»‹nh dáº¡ng [x1, y1, x2, y2]
violation_zone = [300, 1450, 2250, 1820]   # báº¡n cÃ³ thá»ƒ chá»‰nh theo video tháº­t

# ============================
# ğŸ“Š HÃ€M TÃNH IOU GIá»®A XE & VÃ™NG
# ============================
def calculate_iou(box, zone):
    xA = max(box[0], zone[0])
    yA = max(box[1], zone[1])
    xB = min(box[2], zone[2])
    yB = min(box[3], zone[3])

    interArea = max(0, xB - xA) * max(0, yB - yA)
    if interArea == 0:
        return 0.0

    boxArea = (box[2] - box[0]) * (box[3] - box[1])
    zoneArea = (zone[2] - zone[0]) * (zone[3] - zone[1])
    iou = interArea / float(boxArea + zoneArea - interArea + 1e-6)
    return iou

# ============================
# ğŸ§  Xá»¬ LÃ VIDEO CHÃNH
# ============================
def process_video():
    cap = cv2.VideoCapture(VIDEO_PATH)
    if not cap.isOpened():
        print("âŒ KhÃ´ng thá»ƒ má»Ÿ video!")
        return

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (width, height))

    frame_nmr = 0
    results = {}

    print(f"ğŸ“¹ Video {width}x{height} @ {fps}fps")

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_nmr += 1
        results[frame_nmr] = {}

        # Detect phÆ°Æ¡ng tiá»‡n
        detections = coco_model(frame, conf=0.3)[0]
        detections_ = []
        for det in detections.boxes.data.tolist():
            x1, y1, x2, y2, score, class_id = det
            if int(class_id) in vehicles:
                detections_.append([x1, y1, x2, y2, score])

        # Tracking
        if len(detections_) > 0:
            track_ids = mot_tracker.update(np.asarray(detections_))
        else:
            track_ids = mot_tracker.update(np.empty((0, 5)))

        # Váº½ vÃ¹ng vi pháº¡m (mÃ u Ä‘á»)
        cv2.rectangle(frame,
                      (violation_zone[0], violation_zone[1]),
                      (violation_zone[2], violation_zone[3]),
                      (0, 0, 255), 3)
        cv2.putText(frame, "Violation Zone", (violation_zone[0], violation_zone[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        # Náº¿u cÃ³ tÃ­n hiá»‡u Ä‘Ã¨n Ä‘á» tá»« MQTT
        if detecting:
            for track in track_ids:
                x1, y1, x2, y2, track_id = track
                car_box = [x1, y1, x2, y2]
                iou = calculate_iou(car_box, violation_zone)

                if iou > 0.2:
                    # Xe vi pháº¡m
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 3)
                    cv2.putText(frame, f"VIOLATION #{int(track_id)}", (int(x1), int(y1) - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                else:
                    # Xe há»£p lá»‡
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
        else:
            # KhÃ´ng cÃ³ tÃ­n hiá»‡u Ä‘Ã¨n Ä‘á» â†’ chá»‰ hiá»ƒn thá»‹ xe bÃ¬nh thÆ°á»ng
            for track in track_ids:
                x1, y1, x2, y2, track_id = track
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 255, 0), 2)

        # Hiá»ƒn thá»‹ vÃ  ghi file
        cv2.imshow("Traffic Monitoring", cv2.resize(frame, (1280, 720)))
        out.write(frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    out.release()
    cv2.destroyAllWindows()

# ============================
# ğŸ”” MQTT CALLBACKS
# ============================
def on_connect(client, userdata, flags, rc):
    print("âœ… Káº¿t ná»‘i ThingsBoard thÃ nh cÃ´ng!" if rc == 0 else f"âŒ Lá»—i káº¿t ná»‘i: {rc}")
    client.subscribe("v1/devices/me/attributes")
    client.subscribe("v1/devices/me/rpc/request/+")

def on_message(client, userdata, msg):
    global detecting
    payload = msg.payload.decode('utf-8')
    print(f"[MQTT] Nháº­n topic: {msg.topic} | Ná»™i dung: {payload}")

    try:
        data = json.loads(payload)
        if "method" in data and data["method"] == "camera_action":
            color = data["params"]["traffic_light"]
            if color == "ğŸ”´":
                detecting = True
                print("ğŸš¨ ÄÃˆN Äá»! Báº®T Äáº¦U PHÃT HIá»†N VI PHáº M...")
            else:
                detecting = False
                print("ğŸŸ¢ğŸŸ¡ Dá»ªNG NHáº¬N DIá»†N (KHÃ”NG ÄÃˆN Äá»)")
    except Exception as e:
        print("âš ï¸ Lá»—i xá»­ lÃ½ dá»¯ liá»‡u MQTT:", e)

# ============================
# ğŸ CHáº Y CHÆ¯Æ NG TRÃŒNH CHÃNH
# ============================
if __name__ == "__main__":
    client = mqtt.Client()
    client.username_pw_set(ACCESS_TOKEN)
    client.on_connect = on_connect
    client.on_message = on_message
    client.connect(BROKER, PORT, 60)

    # dÃ¹ng vÃ²ng láº·p phá»‘i há»£p video + MQTT
    client.loop_start()
    process_video()
    client.loop_stop()
