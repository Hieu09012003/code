from ultralytics import YOLO
import cv2
import numpy as np
import json
import paho.mqtt.client as mqtt
from sort.sort import *
from util import get_car, read_license_plate, write_csv

# ============================ #
# ‚öôÔ∏è C·∫§U H√åNH MQTT + VIDEO     #
# ============================ #
ACCESS_TOKEN = "1lZGDfQeEZJ7UqV30cTh"   # Token c·ªßa Raspberry Pi device
BROKER = "demo.thingsboard.io"
PORT = 1883

VIDEO_PATH = "./1000.mp4"
OUTPUT_PATH = "./output_violation.mp4"

# ============================ #
# ‚öôÔ∏è C·∫§U H√åNH YOLO & SORT      #
# ============================ #
coco_model = YOLO("yolov8n.pt")
license_plate_detector = YOLO("./models/license_plate.pt")
mot_tracker = Sort()

vehicles = [2, 3, 5, 7]  # car, motorcycle, bus, truck
detecting = False         # b·∫≠t khi c√≥ t√≠n hi·ªáu ƒë√®n ƒë·ªè üî¥

# ============================ #
# üß≠ T·ªåA ƒê·ªò V√ôNG VI PH·∫†M       #
# ============================ #
violation_zone = [300, 1550, 3250, 1820]  # [x1, y1, x2, y2]

# ============================ #
# üìä H√ÄM T√çNH IOU              #
# ============================ #
def calculate_iou(box, zone):
    xA = max(box[0], zone[0])
    yA = max(box[1], zone[1])
    xB = min(box[2], zone[2])
    yB = min(box[3], zone[3])
    interArea = max(0, xB - xA) * max(0, yB - yA)
    if interArea == 0:
        return 0.0
    boxArea = (box[2] - box[0]) * (box[3] - box[1])
    zoneArea = (zone[2] - zone[0]) * (zone[3] - zone[1])
    iou = interArea / float(boxArea + zoneArea - interArea + 1e-6)
    return iou

# ============================ #
# üß† X·ª¨ L√ù VIDEO CH√çNH         #
# ============================ #
def process_video():
    cap = cv2.VideoCapture(VIDEO_PATH)
    if not cap.isOpened():
        print("‚ùå Kh√¥ng th·ªÉ m·ªü video!")
        return

    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (width, height))

    frame_nmr = 0
    results = {}

    print(f"üìπ Video {width}x{height} @ {fps}fps")

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_nmr += 1
        results[frame_nmr] = {}

        # 1Ô∏è‚É£ Detect ph∆∞∆°ng ti·ªán
        detections = coco_model(frame, conf=0.3)[0]
        detections_ = []
        for det in detections.boxes.data.tolist():
            x1, y1, x2, y2, score, class_id = det
            if int(class_id) in vehicles:
                detections_.append([x1, y1, x2, y2, score])

        # 2Ô∏è‚É£ Tracking
        if len(detections_) > 0:
            track_ids = mot_tracker.update(np.asarray(detections_))
        else:
            track_ids = mot_tracker.update(np.empty((0, 5)))

        # 3Ô∏è‚É£ V·∫Ω v√πng vi ph·∫°m
        cv2.rectangle(frame, (violation_zone[0], violation_zone[1]),
                      (violation_zone[2], violation_zone[3]), (0, 0, 255), 3)
        cv2.putText(frame, "Violation Zone",
                    (violation_zone[0], violation_zone[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        # 4Ô∏è‚É£ N·∫øu c√≥ t√≠n hi·ªáu ƒë√®n ƒë·ªè üî¥ ‚Üí ki·ªÉm tra vi ph·∫°m
        if detecting:
            for track in track_ids:
                x1, y1, x2, y2, track_id = track
                car_box = [x1, y1, x2, y2]
                iou = calculate_iou(car_box, violation_zone)

                if iou > 0.1:
                    # üö® Xe vi ph·∫°m
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 3)
                    cv2.putText(frame, f"VIOLATION #{int(track_id)}",
                                (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8,
                                (0, 0, 255), 2)

                    # 5Ô∏è‚É£ Nh·∫≠n di·ªán bi·ªÉn s·ªë cho xe vi ph·∫°m
                    license_plates = license_plate_detector(frame)[0]
                    for license_plate in license_plates.boxes.data.tolist():
                        lx1, ly1, lx2, ly2, score, class_id = license_plate
                        xcar1, ycar1, xcar2, ycar2, car_id = get_car(license_plate, track_ids)

                        if car_id == track_id:
                            lp_crop = frame[int(ly1):int(ly2), int(lx1):int(lx2), :]
                            lp_gray = cv2.cvtColor(lp_crop, cv2.COLOR_BGR2GRAY)
                            _, lp_thresh = cv2.threshold(lp_gray, 64, 255, cv2.THRESH_BINARY_INV)

                            lp_text, lp_score = read_license_plate(lp_thresh)
                            if lp_text:
                                results[frame_nmr][car_id] = {
                                    "car": {"bbox": [xcar1, ycar1, xcar2, ycar2]},
                                    "license_plate": {"bbox": [lx1, ly1, lx2, ly2],
                                                      "text": lp_text,
                                                      "bbox_score": score,
                                                      "text_score": lp_score}
                                }

                                cv2.putText(frame, f"{lp_text}",
                                            (int(lx1), int(ly1) - 10),
                                            cv2.FONT_HERSHEY_SIMPLEX, 1,
                                            (255, 255, 0), 2)
                                cv2.rectangle(frame, (int(lx1), int(ly1)),
                                              (int(lx2), int(ly2)), (255, 0, 0), 2)

                else:
                    # Xe h·ª£p l·ªá
                    cv2.rectangle(frame, (int(x1), int(y1)),
                                  (int(x2), int(y2)), (0, 255, 0), 2)
        else:
            # üü¢üü° Kh√¥ng ƒë√®n ƒë·ªè ‚Üí ch·ªâ theo d√µi b√¨nh th∆∞·ªùng
            for track in track_ids:
                x1, y1, x2, y2, track_id = track
                cv2.rectangle(frame, (int(x1), int(y1)),
                              (int(x2), int(y2)), (255, 255, 0), 2)

        # 6Ô∏è‚É£ Hi·ªÉn th·ªã video
        frame_disp = cv2.resize(frame, (1280, 720))
        cv2.imshow("Traffic Monitoring", frame_disp)
        out.write(frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    write_csv(results, "./violation_results.csv")
    cap.release()
    out.release()
    cv2.destroyAllWindows()

# ============================ #
# üîî MQTT CALLBACKS             #
# ============================ #
def on_connect(client, userdata, flags, rc):
    print("‚úÖ K·∫øt n·ªëi ThingsBoard th√†nh c√¥ng!" if rc == 0 else f"‚ùå L·ªói k·∫øt n·ªëi: {rc}")
    client.subscribe("v1/devices/me/rpc/request/+")

def on_message(client, userdata, msg):
    global detecting
    payload = msg.payload.decode("utf-8")
    print(f"[MQTT] Topic: {msg.topic} | {payload}")

    try:
        data = json.loads(payload)
        if "method" in data and data["method"] == "camera_action":
            color = data["params"]["traffic_light"]
            if color == "üî¥":
                detecting = True
                print("üö® ƒê√àN ƒê·ªé! B·∫ÆT ƒê·∫¶U PH√ÅT HI·ªÜN VI PH·∫†M")
            else:
                detecting = False
                print("üü¢üü° ƒê√àN KH√îNG ƒê·ªé ‚Äî D·ª™NG PH√ÅT HI·ªÜN")
    except Exception as e:
        print("‚ö†Ô∏è L·ªói x·ª≠ l√Ω MQTT:", e)

# ============================ #
# üèÅ CH·∫†Y CH∆Ø∆†NG TR√åNH CH√çNH   #
# ============================ #
if __name__ == "__main__":
    client = mqtt.Client()
    client.username_pw_set(ACCESS_TOKEN)
    client.on_connect = on_connect
    client.on_message = on_message
    client.connect(BROKER, PORT, 60)

    client.loop_start()
    process_video()
    client.loop_stop()
